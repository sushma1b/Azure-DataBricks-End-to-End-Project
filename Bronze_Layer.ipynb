{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3e42433-8ea8-4eec-b220-ff3ec2f241ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"abfss://source@sadec25etlproject.dfs.core.windows.net/orders\")\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6c11e22-bfe6-4e00-b7ac-1cf24adf4c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Data Reading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4048b387-098f-451b-baa2-7fbfcb8bce95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.readStream.format(\"cloudfiles\")\\\n",
    "    .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "    .option(\"cloudFiles.schemaLocation\", \"abfss://bronze@sadec25etlproject.dfs.core.windows.net/checkpoint_orders\")\\\n",
    "    .load(\"abfss://source@sadec25etlproject.dfs.core.windows.net/orders\")\n",
    "#rerun this command everytime when the new data is added to the orders folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e2ed608-65f0-44f1-b801-883c90df7071",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Data Writing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61454bf8-4c4f-455e-b923-1559cfac8b36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.writeStream.format(\"parquet\")\\\n",
    "    .outputMode(\"append\")\\\n",
    "    .option(\"checkpointLocation\", \"abfss://bronze@sadec25etlproject.dfs.core.windows.net/checkpoint_orders\")\\\n",
    "    .option(\"path\", \"abfss://bronze@sadec25etlproject.dfs.core.windows.net/orders\")\\\n",
    "    .trigger(once=True)\\\n",
    "    .start()\n",
    "#rerun this command everytime when the new data is added to the orders folder, and it will only append the new data because \n",
    "#  of trigger once, rocksdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16c71465-987d-4dbf-8c4b-b4cab2777fc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"abfss://bronze@sadec25etlproject.dfs.core.windows.net/orders\")\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebc285c7-5782-410e-9bd5-b099f2e44ed8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **NEXT LEVEL**\n",
    "## **Dynamic Capabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d21f4a5-8a38-40ce-bb34-a3de0e404a99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"file_name\", \"orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cdabd94-c386-492f-8076-6919d0745e15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.get(\"file_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03c1963d-6c47-45da-b9c0-c97bbae469c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "p_file_name = dbutils.widgets.get(\"file_name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1c420de-5bce-46ae-bbd0-585e02358ea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Data Reading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f32d376a-d29b-4b7a-a293-4c10c50202df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.readStream.format(\"cloudfiles\")\\\n",
    "    .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "    .option(\"cloudFiles.schemaLocation\", f\"abfss://bronze@sadec25etlproject.dfs.core.windows.net/checkpoint_{p_file_name}\")\\\n",
    "    .load(f\"abfss://source@sadec25etlproject.dfs.core.windows.net/{p_file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "689208bd-d666-4c30-845b-283cee5a884e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Data Writing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8fb30be-73a7-4b28-844c-47f94ce22960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.writeStream.format(\"parquet\")\\\n",
    "    .outputMode(\"append\")\\\n",
    "    .option(\"checkpointLocation\", f\"abfss://bronze@sadec25etlproject.dfs.core.windows.net/checkpoint_{p_file_name}\")\\\n",
    "    .option(\"path\", f\"abfss://bronze@sadec25etlproject.dfs.core.windows.net/{p_file_name}\")\\\n",
    "    .trigger(once=True)\\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9e66b62-8e91-45d2-b299-f6662636cdfa",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1766296655025}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# cheking the results by passing the file_name from parameter widget box after task success in jobs\n",
    "df = spark.read.format(\"parquet\")\\\n",
    "    .load(f\"abfss://bronze@sadec25etlproject.dfs.core.windows.net/{p_file_name}\")\n",
    "df.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze_Layer",
   "widgets": {
    "file_name": {
     "currentValue": "customers",
     "nuid": "194126e0-27b5-445a-ac14-5c85b652399d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "orders",
      "label": null,
      "name": "file_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "orders",
      "label": null,
      "name": "file_name",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
